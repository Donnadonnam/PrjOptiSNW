---
title: "Linear Preference, Feasible llocation, Allocate by Kids, Marry, Consider <= 65"
output:
  html_notebook:
    toc: yes
---

```{r setup, include=FALSE}
rm(list = ls())

knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(fig.width=12, fig.height=8)

library(tidyverse)
library(REconTools)
```

# Optimal Allocation Y, J and M

2019 Income, Kids Count and Martial Status (non-stochastic) based optimal linear allocation (Utilitarian).

## Process Simulation Outputs

### Define Some Parameters

```{r}
# Max Phase Out given 1200*2 + 500*4 = 4400
fl_max_phaseout = 238000
it_bin_dollar_before_phaseout = 2500
# Dollar Per Check
fl_percheck_dollar = 100
# Meaning of Ymin Ymax simulated interval of 1
fl_multiple = 58056
# Number of Max Checks
it_max_checks = 44
# Number of Tax Paying Households
fl_tax_hh = 128580000
# Number of Income Groups to Use: use 25 for 10,000 = 1
# Age Conditions
# it_max_age = 64
# it_min_age = 64
it_max_age = 64
it_min_age = 18
```

### Variable Names and Paths

```{r}
# File Path
spt_root <- 'C:/Users/fan/Documents/Dropbox (UH-ECON)/PrjNygaardSorensenWang/'
srt_csv_test_path <- paste0(spt_root,'PrjOptiSNW/AllocateR/alloc_discrete_lbl/feasible_csv/')
srt_simu_path <- paste0(spt_root, 'Output/')
# File Name
# snm_simu_csv <- 'snwx_v_planner_small.csv'
# snm_simu_csv <- 'snwx_v_planner_small_dup.csv'
# snm_simu_csv <- 'snwx_v_planner_base.csv'
# snm_simu_csv <- 'snwx_v_planner_dense.csv'
# snm_simu_csv <- 'snwx_v_planner_densemore.csv'
# st_file_type <- 'small_dup'
# st_file_type <- 'dense'
# st_file_type <- 'moredense'
# st_file_type <- 'densemore_a55z133'
# st_file_type <- 'densemore_a55z266_e0m0'
# st_file_type <- 'moredense_a55zh43zs11'
# st_file_type <- 'moredense_a75zh101zs5'

# 1. e1m1 very dense a and zh test, single, lower edu only
# st_file_type <- 'moredense_a100zh266_e1m1'

# 2. e1m1 very dense a and zh test, both married and education, no spouse shock
# st_file_type <- 'moredense_a100zh266_e2m2'
# st_file_type <- 'moredense_a100zh81zs5_e2m2'
# st_file_type <- 'moredense_a65zh133zs5_e2m2'
# st_file_type <- 'moredense_a65zh266zs5_e2m2'
st_file_type <-   'moredense_a65zh266zs5_e2m2_b0_calibrated'
# st_file_type <- 'dense_ybin2500'

# CSV Name
snm_simu_csv <- paste0('snwx_v_planner_',st_file_type,'.csv')

# Column Names
ar_svr_csv <- c('age', 'marital', 'kids', 'checks',	'ymin', 'mass', 'survive', 'vtilde', 'ctilde')
# Variables That Identify Individual Types
ar_svr_groups <- c('marital', 'kids', 'ymin_group')
ar_svr_groups_stats <- c('mass', 'survive')
# Number of Checks and Planner Value
svr_checks <- 'checks'
svr_v_value <- 'vtilde'
svr_c_value <- 'ctilde'
```

### Read Input CSV Data

Drop any:

1. zero mass: vtilde is zero (should have already been dropped)
2. infeasible check: given 1200 dollar per spouse, and 500 per child, and 4 child at most, 44 check is the maximum.

Note:

*filter(checks <= it_max_checks)* will keep 1 more than actual, this is before differencing happening later.

```{r}
df_plan_v_tilde <- as_tibble(read.csv(paste0(srt_simu_path, snm_simu_csv), header=FALSE)) %>%
  rename_all(~c(ar_svr_csv)) %>%
  filter(vtilde != 0) %>%
  filter(checks <= it_max_checks) %>%
  filter(age <= it_max_age) %>%
  filter(age >= it_min_age)

# Column 1: Age (in year before COVID)
# Column 2: Marital status (0 if not married; 1 if married)
# Column 3: Nr of kids (0, 1, ..., 5) where 5 means 5 or more
# Column 4: Number of welfare checks (here either equal to 0 or 1)
# Column 5 and column 6 give income range
# So the individual's income is at least as large as the value in column 5 but strictly less than the value in column 6
# Column 7: Population weight Of that particular group (in the stationary distribution)
# Column 8: Survival probability of that particular age (since the planner knows that some of the individuals will die before next period, so wasn't sure how you wanted me to include that. I did not already include it in V^tilde)
# Column 9: Value of planner as in the slides (with the exception that I didn't multiply by the survival probability
```

Summarize Dataframe:

```{r}
# REconTools::ff_summ_percentiles(df_plan_v_tilde)
```

Total Mass Check, and Total Check Measures Check ( 1 + total check possible, difference later):

```{R}
sum(df_plan_v_tilde %>% pull(mass))
```

## Aggregatations

### Aggregation over Age

Suppose the Planner does not observe Age (or can not use age information for allocation). This requires generating a weighted-average over ages conditional on income, kids count and marital status:

```{r}
dim(df_plan_v_tilde)
# df_plan_v_tilde_yjm <- df_plan_v_tilde
df_plan_v_tilde_yjm <- df_plan_v_tilde %>%
  group_by(marital, kids, checks, ymin) %>%
  summarize(vtilde = sum(vtilde*mass)/sum(mass),
            ctilde = sum(ctilde*mass)/sum(mass),
            mass = sum(mass),
            survive = mean(survive)) %>%
  ungroup()

# Remove
# rm(df_plan_v_tilde)

# Summarize
dim(df_plan_v_tilde_yjm)
# REconTools::ff_summ_percentiles(df_plan_v_tilde_yjm)
```

Mass Check:

```{R}
sum(df_plan_v_tilde_yjm %>% pull(mass))
```

### Aggregate Over Income Groups

Generate Income Groups, and weighted sum again. The matlab code generates 201 income groups. If we simulate with thousands of shock points, we should show optimal results for each one of the 201 income groups. When the number of shock points are, however, limited, we end up often with a few shock and savings combinations in some of the income bins. In income bins that are adjacent, one bin might have a dozen shock and savings combinations, another bin might only have one.

Note, the way the income groups work is the following:

- We generated income from 0 to 7
- Ymin goes from 0.35 to 7: 7 refers to 7*58056=406392 dollars in 2012USD.
- For less precise version of solution, solved at 200 bins, each bin = 0.035, 0.035*58056=2031.96
- For more precise version of solution, solved roughly at 500 dollar intervals before phase out of 238000.
- 4*58056 = 232224
- linspace(0,3.99,115) is all segments at 0.035 interval before 23 thousand, or 3.99
- Divide these into 20 bins, at 0.21 interval between 0 and 3.99, each 0.21 is 0.21*58056=12191 12k
- But data does not start at zero for ymin.
- 238000 is the maximum phase out income level, no checks will be received by any households beyond $238000.
- 238000/58056 = 4.09949

Generate Some Income bin Information:

```{r}
# Number of Cuts Before th Mas Phase Out Point.
fl_thres = fl_max_phaseout/fl_multiple
# Solution Grid Precision prior to max_phaseout point.
inc_grid1 = seq(0, fl_thres, length.out=(fl_max_phaseout)/it_bin_dollar_before_phaseout)
fl_grid_gap = inc_grid1[2] - inc_grid1[1]
# Not all inc_grid1 points are valid, there are some elements that have no mass
fl_min_ymin_posmass = min(df_plan_v_tilde_yjm %>% pull(ymin))
# First group is min
ar_ycut = c(0, inc_grid1[inc_grid1>fl_min_ymin_posmass+fl_grid_gap], 7)

# alternative method
# fl_max_full_phaseout = fl_max_phaseout/fl_multiple
# ar_ycut2 = c(0, seq(
#   min(df_plan_v_tilde_yjm %>% pull(ymin)),
#   fl_max_full_phaseout,
#   length.out=(it_inc_groups - 1))[2:(it_inc_groups - 1)], 7)

# ar_ycut = c(0, seq(
#   min(df_plan_v_tilde_yjm %>% pull(ymin)),
#   7,
#   length.out=(it_inc_groups - 1))[2:(it_inc_groups - 1)])

print(ar_ycut*fl_multiple)
it_inc_groups = length(ar_ycut)
fl_inc_gap = (ar_ycut[3]-ar_ycut[2])*fl_multiple
fl_inc_min = min(df_plan_v_tilde_yjm %>% pull(ymin))*fl_multiple
subtitle = paste0('1 unit along x-axis = $', round(fl_inc_gap),
                  ', x-axis min = $', round(fl_inc_min),
                  ', x-axis final group >= $', round(ar_ycut[length(ar_ycut)-1]*fl_multiple))
print(subtitle)
```

Weighted averaging to generate larger income groups that contain sufficient mass to appropriately approximate results:

```{r}
# df_plan_v_tilde_ygrpjm %>% filter(kids==0 & checks == 1)
# table(df_plan_v_tilde_ygrpjm$ymin_group)
# df_plan_v_tilde_ygrpjm <- df_plan_v_tilde_yjm %>% mutate(ymin_group = as.factor(ymin))
df_plan_v_tilde_ygrpjm <- df_plan_v_tilde_yjm %>%
  mutate(ymin_group = (cut(ymin, ar_ycut))) %>%
  group_by(marital, kids, checks, ymin_group) %>%
  summarize(vtilde = sum(vtilde*mass)/sum(mass),
            ctilde = sum(ctilde*mass)/sum(mass),
            mass = sum(mass),
            survive = mean(survive)) %>%
  ungroup()

# Remove
# rm(df_plan_v_tilde_yjm)

# Summarize
REconTools::ff_summ_percentiles(df_plan_v_tilde_ygrpjm)
```

Mass Check:

```{r}
sum(df_plan_v_tilde_ygrpjm %>% pull(mass))
```

## Generate ID and Value Dataframes

### Generate Unique ID dataframe

Split dataframe, so that there is one dataframe with just ID information. And there is another dataframe with ID and associated check, values, and mass. Within each group, there are multiple checks possibly.

First, generate Group IDs, unique ID for each individual income-group, kids, and marital status:

```{r}
# group id
svr_group_id <- 'group_id'
# Define
ls_svr_group_vars <- ar_svr_groups
# panel dataframe following
df_plan_v_tilde_id <- df_plan_v_tilde_ygrpjm %>%
  arrange(!!!syms(ls_svr_group_vars)) %>%
  group_by(!!!syms(ls_svr_group_vars)) %>%
  mutate(!!sym(svr_group_id) := (row_number()==1)*1) %>%
  ungroup() %>%
  rowid_to_column(var = "id") %>%
  mutate(!!sym(svr_group_id) := cumsum(!!sym(svr_group_id))) %>%
  select(one_of(svr_group_id, ls_svr_group_vars), everything())
REconTools::ff_summ_percentiles(df_plan_v_tilde_id)
```

Second, stats Check of ID frame:

```{r}
REconTools::ff_summ_count_unique_by_groups(df_plan_v_tilde_id,ls_svr_group_vars,svr_group_id)
REconTools::ff_summ_percentiles(df_plan_v_tilde_id, bl_statsasrows = FALSE)
```

Third, generate ID frame with unique row.

```{r}
# Select Grouping by Variables
df_id <- df_plan_v_tilde_id %>%
  select(one_of(svr_group_id, ls_svr_group_vars, ar_svr_groups_stats)) %>%
  group_by(!!!syms(svr_group_id)) %>%
  slice_head() %>% ungroup() %>%
  select(one_of(svr_group_id, ls_svr_group_vars, ar_svr_groups_stats)) %>%
  rename(id_i = !!sym(svr_group_id))
ar_group_ids <- unique(df_id %>% pull(id_i))
# Summarize
REconTools::ff_summ_percentiles(df_id)
```

Mass Check (sums up to measure 1, no duplicates for checks):

```{R}
sum(df_id %>% pull(mass))
```

### Check Value Dataframe all Checks

Dataframew with ID, check, mass and values

```{r}
# Select 4 variables
df_value <- df_plan_v_tilde_id %>%
  select(one_of(svr_group_id, svr_checks, svr_v_value, svr_c_value))
# remove
# rm(df_plan_v_tilde_id)
# Summarize
REconTools::ff_summ_percentiles(df_value)
REconTools::ff_summ_count_unique_by_groups(df_value, svr_group_id, svr_group_id)
```

## Generate Dataframe Inputs for the Allocation Problem

Restructure the value dataframe slightly so that it can be used with the allocation functions. Note that the output structure has an *A* column and an *alpha* column, and starts counting *checks* at 1. For the check = 1 row, *A* is the value without the check, and *alpha* is the marginal effects of the checks.

### Generate IL Dataframe Core

```{r}
# 1. id column and id_il
df_il <- df_value %>% rename(id_i = !!sym(svr_group_id)) %>%
  mutate(id_il = row_number()) %>%
  select(id_i, id_il, everything())
# 2. D_max_i and D_il
df_il <- df_il %>%
  arrange(id_i, svr_checks) %>% group_by(id_i) %>%
  mutate(D_max_i = max(!!sym(svr_checks))) %>%
  rename(D_il = !!sym(svr_checks)) %>%
  mutate(beta_i = 1/n()) %>%
  select(id_i, id_il, D_max_i, D_il, everything())
# Summarize
REconTools::ff_summ_percentiles(df_il)
```

### Generate IL Dataframe for Utility

Generate A and alpha:

```{r}
# 3. A_il and alpha_il
df_il_U <- df_il %>%
  mutate(c_alpha_il = lead(!!sym(svr_c_value)) - (!!sym(svr_c_value)),
         v_alpha_il = lead(!!sym(svr_v_value)) - (!!sym(svr_v_value))) %>%
  rename(c_A_il = !!sym(svr_c_value),
         v_A_il = !!sym(svr_v_value)) %>%
  ungroup()

# 4. drop max check
df_il_U <- df_il_U %>%
  filter(D_il != max(df_il$D_il)) %>%
  mutate(D_il = D_il + 1)
```

Summarize:

```{r}
# https://fanwangecon.github.io/PrjOptiAlloc/reference/df_opt_caschool_input_il.html
# id_i id_il D_max_i  D_il  A_il alpha_il  beta_i
head(df_il_U, 50)
tail(df_il_U, 50)
# Summarize
REconTools::ff_summ_percentiles(df_il_U)
```

#### Rescale Dataframe

Utility could be negative, inequality usually considered over positive outcomes. We can rescale utility to be positive. The extreme Rawlsian only cares about relative $A$ and the utilitarian only cares about $\alpha$, so in some sense, shifting the utility levels up do not really matter. In principle inequality of Utils makes sense but there is no clear scale. Hence inequality over consumption, income other other types of outcomes with hard-scales could be easier to interpret.

To make future comparisons reasonable, will increase all utility up by 25 units, if utility is below -25, set to 25.

```{r}

# Rescale to 0
# rescaling by zero, this means we can correctly calculate v
# df_il_U <- df_il_U %>%
#   mutate(v_A_il = 0)

# Minimum A
fl_min_v_A_il <- min(df_il_U$v_A_il) + 0.01
# Rescale by minimum
df_il_U <- df_il_U %>%
  mutate(v_A_il = v_A_il - fl_min_v_A_il)

# Summarize
REconTools::ff_summ_percentiles(df_il_U)
```

## Preference Vector

Preference vectors:

```{r}
ar_rho <- 1 - (10^(c(seq(-2,2, length.out=4))))
ar_rho <- unique(c(1,ar_rho))
# ar_rho <- c(1)
```

## Select Random Subset (Or All)

select data subset or All:

```{r, fig.width=5, fig.height=5}
# subset select
set.seed(123)
it_draw <- length(ar_group_ids)
# it_draw <- 2
ar_group_rand <- ar_group_ids[sample(length(ar_group_ids), it_draw, replace=FALSE)]
df_input_il <- df_il_U %>%
  filter(id_i %in% ar_group_rand) %>%
  mutate(id_il = row_number())
# Summarize
REconTools::ff_summ_percentiles(df_input_il)
```


## Adjust alpha, Non-increasing Marginal Effects

Adjust approximation jumps, there are some minor approximation errors. These errors mean that the marginal effects might not be non-increasing, there could be very tiny jumps in the marginal value of consumption or value.

Are these arrays below non-increasing? Individual 50 clearly downward shifting marginal value, but individual 14's marginal values almost constant, and very very tiny not real change flucations. Individual 50 is much poorer than individual 14.

### Adjust alpha to make it non-increasing

```{r, eval=FALSE}
# # Get C and V Marginal Arrays
# ar_id14_v_alpha <- df_input_il %>% filter(id_i == 14) %>% pull(v_alpha_il)
# ar_id14_c_alpha <- df_input_il %>% filter(id_i == 14) %>% pull(c_alpha_il)
# ar_id50_v_alpha <- df_input_il %>% filter(id_i == 50) %>% pull(v_alpha_il)
# ar_id50_c_alpha <- df_input_il %>% filter(id_i == 50) %>% pull(c_alpha_il)
# # Differences in marginals
# ar_id14_v_alpha_dif <- diff(ar_id14_v_alpha)
# ar_id14_c_alpha_dif <- diff(ar_id14_c_alpha)
# ar_id50_v_alpha_dif <- diff(ar_id50_v_alpha)
# ar_id50_c_alpha_dif <- diff(ar_id50_c_alpha)
# # Number of points where marginals are increasing?
# print(sum(ar_id14_v_alpha_dif>0))
# print(sum(ar_id14_c_alpha_dif>0))
# print(sum(ar_id50_v_alpha_dif>0))
# print(sum(ar_id50_c_alpha_dif>0))
# # Magnitude of increases
# print(max(ar_id14_v_alpha_dif))
# print(max(ar_id14_c_alpha_dif))
# print(max(ar_id50_v_alpha_dif))
# print(max(ar_id50_c_alpha_dif))
# # Magnitude of decreases
# print(min(ar_id14_v_alpha_dif))
# print(min(ar_id14_c_alpha_dif))
# print(min(ar_id50_v_alpha_dif))
# print(min(ar_id50_c_alpha_dif))
```

Strategies to deal with the problem, due to very large number of small increasing points, up to many many decimal points.

```{r, eval=FALSE}
# rounding = 10
# # Get C and V Marginal Arrays
# ar_id14_v_alpha <- df_input_il %>% filter(id_i == 159) %>% pull(v_alpha_il)
# ar_id14_c_alpha <- df_input_il %>% filter(id_i == 159) %>% pull(c_alpha_il)
# ar_id50_v_alpha <- df_input_il %>% filter(id_i == 207) %>% pull(v_alpha_il)
# ar_id50_c_alpha <- df_input_il %>% filter(id_i == 207) %>% pull(c_alpha_il)
# # Differences in marginals
# ar_id14_v_alpha_dif <- diff(ar_id14_v_alpha)
# ar_id14_c_alpha_dif <- diff(ar_id14_c_alpha)
# ar_id50_v_alpha_dif <- diff(ar_id50_v_alpha)
# ar_id50_c_alpha_dif <- diff(ar_id50_c_alpha)
# # Number of points where marginals are increasing?
# print(sum(ar_id14_v_alpha_dif>0))
# print(sum(ar_id14_c_alpha_dif>0))
# print(sum(ar_id50_v_alpha_dif>0))
# print(sum(ar_id50_c_alpha_dif>0))
```

Cumulative sum for correction:

```{r, eval=FALSE}
# fl_min_inc_bd <- 1e-20
# ar_cur <- ar_id14_v_alpha
# ar_cur_diff <- diff(ar_cur)
# # New Array of NAs
# ar_cur_df_adj <- rep(NA, length(ar_cur_diff))
# # No changes needed if difference is negative, or zero, non-increasing
# ar_cur_df_adj[ar_cur_diff<=0] = 0
# # Record changes if positive
# ar_cur_df_adj[ar_cur_diff>0] = ar_cur_diff[ar_cur_diff>0]
# # Cumulative sum adjustment needed
# ar_cur_adj_cumsum <- cumsum(ar_cur_df_adj)
# ar_cur_adj_cumsum <- c(0, ar_cur_adj_cumsum);
# # Add adjustment to original array
# ar_cur_adj <- ar_cur - ar_cur_adj_cumsum
# # Make sure Adjusted changes are non-negative
# ar_cur_adj[ar_cur_adj < fl_min_inc_bd] = fl_min_inc_bd
# # show
# plot(seq(1,44), ar_cur, col='blue')
# par(new=T)
# plot(seq(1,43), ar_cur_diff, col='black')
# par(new=T)
# plot(seq(1,44), ar_cur_adj, col='red')
```

### Alpha Adjustment Function

```{r}
ffi_alpha_non_increasing_adj <- function(ar_alpha, fl_min_inc_bd = 1e-20) {
  # alpha has tiny upticks sometimes due to approximation errors, need to be adjusted
  # Following theorem 1, alpha must be non-increasing.

  ar_cur <- ar_alpha
  ar_cur_diff <- diff(ar_cur)
  # New Array of NAs
  ar_cur_df_adj <- rep(NA, length(ar_cur_diff))
  # No changes needed if difference is negative, or zero, non-increasing
  ar_cur_df_adj[ar_cur_diff<=0] = 0
  # Record changes if positive
  ar_cur_df_adj[ar_cur_diff>0] = ar_cur_diff[ar_cur_diff>0]
  # Cumulative sum adjustment needed
  ar_cur_adj_cumsum <- cumsum(ar_cur_df_adj)
  ar_cur_adj_cumsum <- c(0, ar_cur_adj_cumsum);
  # Add adjustment to original array
  ar_cur_adj <- ar_cur - ar_cur_adj_cumsum
  # Make sure Adjusted changes are non-negative
  ar_cur_adj[ar_cur_adj < fl_min_inc_bd] = fl_min_inc_bd

  # return
  return(ar_cur_adj)
}

# # Test Function array 1
# ar_id14_v_alpha_adj <- ffi_alpha_non_increasing_adj(ar_id14_v_alpha)
# plot(seq(1,44), ar_id14_v_alpha, col='blue')
# par(new=T)
# plot(seq(1,44), ar_id14_v_alpha_adj, col='black')
# # Test Function array 2
# ar_id14_c_alpha_adj <- ffi_alpha_non_increasing_adj(ar_id14_c_alpha)
# plot(seq(1,44), ar_id14_c_alpha, col='blue')
# par(new=T)
# plot(seq(1,44), ar_id14_c_alpha_adj, col='black')
# # Test Function array 3
# ar_id50_v_alpha_adj <- ffi_alpha_non_increasing_adj(ar_id50_v_alpha)
# plot(seq(1,44), ar_id50_v_alpha, col='blue')
# par(new=T)
# plot(seq(1,44), ar_id50_v_alpha_adj, col='black')
# # Test Function array 4
# ar_id50_c_alpha_adj <- ffi_alpha_non_increasing_adj(ar_id50_c_alpha)
# plot(seq(1,44), ar_id50_c_alpha, col='blue')
# par(new=T)
# plot(seq(1,44), ar_id50_c_alpha_adj, col='black')
```


### Apply alpha Adjustment Function over Dataframe

```{r}
bl_non_inc_adjust = TRUE
if (bl_non_inc_adjust){
  # Update c_alpha_il
  df_input_il_noninc <- df_input_il %>%
    group_by(id_i) %>%
    do(c_alpha_il_noninc = ffi_alpha_non_increasing_adj(.$c_alpha_il)) %>%
    unnest(c(c_alpha_il_noninc)) %>%
    group_by(id_i) %>%
    mutate(D_il = row_number()) %>%
    left_join(df_input_il, by=(c('id_i'='id_i', 'D_il'='D_il')))

  # Update v_alpha_il
  df_input_il_noninc <- df_input_il_noninc %>%
    group_by(id_i) %>%
    do(v_alpha_il_noninc = ffi_alpha_non_increasing_adj(.$v_alpha_il)) %>%
    unnest(c(v_alpha_il_noninc)) %>%
    group_by(id_i) %>%
    mutate(D_il = row_number()) %>%
    left_join(df_input_il_noninc, by=(c('id_i'='id_i', 'D_il'='D_il')))

  # replace
  df_input_il_noninc <- df_input_il_noninc %>%
    select(-c_alpha_il, -v_alpha_il) %>%
    rename(c_alpha_il = c_alpha_il_noninc) %>%
    rename(v_alpha_il = v_alpha_il_noninc)
} else {
  df_input_il_noninc <- df_input_il
}
```


## Actual Policy as Alternative Allocation

### Actual Policy Function

We have 10 household structure categories, provide checks based on VOX article to the 10 household structures. For each household type different numbers of checks are provided given the income level. A problem is that a precisely computed income axis is needed to match the VOX chart properly, given fewer points, have to approximate.

Create a function, that takes as inputs the number of kids and marrital status. Given the current group's bounds on income, compute the average check number.

First, what is the maximum phase out level:

```{r}
# Receive at Most
fl_max_checks <- 1200*2+4*500
# Max Phase Out Group
fl_mas_start_drop <- 150000
# Drop rate
fl_drop_rate <- 5/100
# max Phase
fl_phase_out_max <- fl_mas_start_drop + fl_max_checks/fl_drop_rate
print(fl_phase_out_max)
```

```{r}
ffi_vox_checks_ykm <- function(ymin_group, marital, kids,
                               ar_ycut,
                               fl_multiple = 58056, fl_percheck_dollar = 100,
                               it_inc_subgroups = 10) {
  # marital 0 or 1
  # kids 0,1,2,3
  # ymin_group index from 1 to N

  # income minimum and maximum,
  # by construction: length(ar_ycut_dollar) = max(ymin_group) + 1
  ar_ycut_dollar = ar_ycut*fl_multiple
  it_ygroups = length(ar_ycut_dollar)

  # Default no checks
  fl_check_dollor = 0

  # Only provide checks if not in the last income group, where all receive none
  if (ymin_group < it_ygroups - 1) {

    # start point household head
    fl_check_dollar = 1200

    # married household gets more, marital = 0, 1
    fl_check_dollar = fl_check_dollar + marital*1200

    # Households with kids: 0, 1,2,3,4
    fl_check_dollar = fl_check_dollar + kids*500


    # lower and upper bounds on income
    fl_inc_group_lower_bound = ar_ycut_dollar[ymin_group]
    fl_inc_group_upper_bound = ar_ycut_dollar[ymin_group+1]

    # A grid of income between these two points: 10 points
    ar_inc_grid = seq(fl_inc_group_lower_bound, fl_inc_group_upper_bound,
                      length.out=it_inc_subgroups)

    # What is the tax rate at each point of these incomes given marry and kids?
    ar_check_reduce_inc_grid = matrix(data=NA, nrow=length(ar_inc_grid), ncol=1)

    # as income increases, fl_check_dollar go down
    it_ctr = 0
    for (fl_inc in ar_inc_grid) {

      it_ctr = it_ctr + 1

      if (marital == 0 && kids == 0) {
        # The benefit would start decreasing at a rate of $5 for every additional $100 in income
        fl_check_reduce = ((max(fl_inc - 75000,0))/100)*5
      }

      # phaseout starts $112,500 for heads of household
      if (marital == 0 && kids != 0) {
        # The benefit would start decreasing at a rate of $5 for every additional $100 in income
        fl_check_reduce = ((max(fl_inc - 112500,0))/100)*5
      }

      # phaseout starts $150,000 for heads of household
      if (marital == 1 ) {
        # The benefit would start decreasing at a rate of $5 for every additional $100 in income
        fl_check_reduce = ((max(fl_inc - 150000,0))/100)*5
      }

      ar_check_reduce_inc_grid[it_ctr] = max(0, fl_check_dollar - fl_check_reduce)

    }

    fl_check_dollor = mean(ar_check_reduce_inc_grid)

  }

  # Check Numbers
  fl_avg_checks = round(fl_check_dollor/fl_percheck_dollar, 0)

  return(fl_avg_checks)
}
# Poorest married 4 kids
ffi_vox_checks_ykm(1,1,4, ar_ycut, fl_multiple, fl_percheck_dollar)
# Test Function
ffi_vox_checks_ykm(2,0,0, ar_ycut, fl_multiple, fl_percheck_dollar)
ffi_vox_checks_ykm(2,1,1, ar_ycut, fl_multiple, fl_percheck_dollar)
ffi_vox_checks_ykm(2,1,3, ar_ycut, fl_multiple, fl_percheck_dollar)
ffi_vox_checks_ykm(2,1,3, ar_ycut, fl_multiple, fl_percheck_dollar)
# Test Function
ffi_vox_checks_ykm(4,0,0, ar_ycut, fl_multiple, fl_percheck_dollar)
ffi_vox_checks_ykm(4,1,1, ar_ycut, fl_multiple, fl_percheck_dollar)
ffi_vox_checks_ykm(4,1,3, ar_ycut, fl_multiple, fl_percheck_dollar)
ffi_vox_checks_ykm(4,1,3, ar_ycut, fl_multiple, fl_percheck_dollar)
# Test Function
ffi_vox_checks_ykm(11,0,0, ar_ycut, fl_multiple, fl_percheck_dollar)
ffi_vox_checks_ykm(11,1,1, ar_ycut, fl_multiple, fl_percheck_dollar)
ffi_vox_checks_ykm(11,1,3, ar_ycut, fl_multiple, fl_percheck_dollar)
ffi_vox_checks_ykm(11,1,3, ar_ycut, fl_multiple, fl_percheck_dollar)
```

### Assign Checks Based on Actual POlicy

```{r}
df_input_il_covid_actual <- df_input_il_noninc %>%
  left_join(df_id, by = "id_i") %>%
  mutate(ymin_group = as.numeric(ymin_group)) %>%
  ungroup() %>% rowwise() %>%
  mutate(actual_checks =
           ffi_vox_checks_ykm(ymin_group, marital, kids,
                              ar_ycut, fl_multiple, fl_percheck_dollar)) %>%
  ungroup()
```

Summarize:

```{r}
# Summarize:
REconTools::ff_summ_percentiles(df_input_il_covid_actual)
# Group Summarize:
ls_svr_group_vars_cact <- c('ymin_group', 'marital', 'kids')
REconTools::ff_summ_bygroup(
  df_input_il_covid_actual, ls_svr_group_vars_cact, 'actual_checks')$df_table_grp_stats
# Group Summarize:
REconTools::ff_summ_bygroup(df_input_il_covid_actual, c('ymin_group'), 'actual_checks')$df_table_grp_stats
REconTools::ff_summ_bygroup(df_input_il_covid_actual, c('marital'), 'actual_checks')$df_table_grp_stats
REconTools::ff_summ_bygroup(df_input_il_covid_actual, c('kids'), 'actual_checks')$df_table_grp_stats
```

### Measure of Check given Mass of People in Each Group

This provides us with the total number of checks that is available in aggregate that is consistent with our simulated population sizes as well as the observed conditional check policies.

Check Mass Sum (should equal check count):

```{r}
mass_sum <- df_input_il_covid_actual %>% summarize(mass_sum = sum(mass))
fl_cost_max_checks_all <- mass_sum*fl_percheck_dollar*fl_tax_hh
st_covid_check_cost <- paste0('Cost All Max Checks=$', round(fl_cost_max_checks_all/1000000000,2),
                              ' bil (assume ',round(fl_tax_hh/1000000,2),' mil tax households)')
print(st_covid_check_cost)
```

Sort by queue ranking and generate cumulative sun of mass along the queue, how many queued position should there be? Combinations of age, kids, marital, income group and check level:


```{r}
mass_sum_covid_vox_actual <- df_input_il_covid_actual %>%
  filter(actual_checks >= D_il) %>%
  summarize(mass_cumsum = sum(mass))
fl_cost_actual <- mass_sum_covid_vox_actual*fl_percheck_dollar*fl_tax_hh
st_covid_check_cost <- paste0('VOX Policy Cost=$', round(fl_cost_actual/1000000000,2),
                              ' bil (assume ',round(fl_tax_hh/1000000,2),
                              ' mil tax households, use SNW 2020 simulated P(Kids, Marry, Income))')
print(st_covid_check_cost)
```

### Allocation Frame with Actual Vox Allocations

If allocation is positive, that means: *D_il = actual_checks*, keep those rows, the *A* And *alpha* in those rows are correct. If *actual_checks = 0*, that means we need to use row were *D_il=1*, but replace the alpha value there by zero.

```{r}
# 2020 consumption
df_input_ib_c <- df_input_il_covid_actual %>%
  filter(case_when(actual_checks == 0 ~ D_il == 1, # if check = 0, filter D_il = 1
                   TRUE ~ D_il == actual_checks)) %>%
  rename(A_i_l0 = c_A_il) %>%
  mutate(alpha_o_i = case_when(actual_checks == 0 ~ 0,
                               TRUE ~ c_alpha_il)) %>%
  select(id_i, A_i_l0, alpha_o_i, beta_i, mass, actual_checks) %>%
  mutate(mass_i = mass, beta_i = 1)


# value
df_input_ib_v <- df_input_il_covid_actual %>%
  filter(case_when(actual_checks == 0 ~ D_il == 1, # if check = 0, filter D_il = 1
                   TRUE ~ D_il == actual_checks)) %>%
  rename(A_i_l0 = v_A_il) %>%
  mutate(alpha_o_i = case_when(actual_checks == 0 ~ 0,
                               TRUE ~ v_alpha_il)) %>%
  select(id_i, A_i_l0, alpha_o_i, beta_i, mass, actual_checks) %>%
  mutate(mass_i = mass, beta_i = 1)

# summarize
REconTools::ff_summ_percentiles(df_input_ib_c)
REconTools::ff_summ_percentiles(df_input_ib_v)
```


## Optimal Feasible Allocation

### Total Check Amount

First Allocation based on 2020 Consumption:

What is the check budget? Naively, for this ignore population weights for different groups, just sum up total check counts from the actual allocation results as if the weights are the same for all groups.

```{r}
# Total checks
it_total_checks <- df_input_il_covid_actual %>%
  filter(D_il == 1) %>%
  summarize(total_checks = sum(actual_checks))
it_total_checks <- as.numeric(it_total_checks)
# this is the measure of checks available given VOX allocation and simulated mass
# And this point, the number is not important
fl_dis_w <- it_total_checks
fl_dis_w_mass <- as.numeric(mass_sum_covid_vox_actual)
print(paste0('fl_dis_w_mass:', fl_dis_w_mass))
print(paste0('fl_dis_w:', fl_dis_w))
```

### Run Allocation Function

#### Discrete Based Allocation

Equal mass assumption for each type.

##### Discrete C Allocation Run

```{r}
# Inputs
# 30 individuals 25 checks, half the amount is available
df_input_il_c <- df_input_il_noninc %>%
  rename(A_il = c_A_il) %>%
  rename(alpha_il = c_alpha_il) %>%
  select(-v_A_il, -v_alpha_il) %>%
  mutate(beta_i = 1) %>%
  ungroup()

# Solve with Function
ls_dis_solu_c <- suppressWarnings(suppressMessages(
  ffp_opt_anlyz_rhgin_dis(ar_rho,
                          fl_dis_w,
                          df_input_il_c,
                          bl_df_alloc_il = FALSE,
                          bl_return_V = TRUE,
                          bl_return_allQ_V = FALSE,
                          bl_return_inner_V = FALSE)))
df_queue_il_long_c <-ls_dis_solu_c$df_queue_il_long
df_alloc_i_long_c <- ls_dis_solu_c$df_alloc_i_long
df_rho_gini_c <- ls_dis_solu_c$df_rho_gini
```

##### Discrete V Allocation Run

Second Allocation based on life-time utility:

```{r}
# Inputs
# 30 individuals 25 checks, half the amount is available
df_input_il_v <- df_input_il_noninc %>%
  rename(A_il = v_A_il) %>%
  rename(alpha_il = v_alpha_il) %>%
  select(-c_A_il, -c_alpha_il) %>%
  mutate(beta_i = 1) %>%
  ungroup()

# Solve with Function
ls_dis_solu_v <- suppressWarnings(suppressMessages(
  ffp_opt_anlyz_rhgin_dis(ar_rho,
                          fl_dis_w,
                          df_input_il = df_input_il_v,
                          bl_df_alloc_il = FALSE,
                          bl_return_V = TRUE,
                          bl_return_allQ_V = FALSE,
                          bl_return_inner_V = FALSE)))
df_queue_il_long_v <-ls_dis_solu_v$df_queue_il_long
df_alloc_i_long_v <- ls_dis_solu_v$df_alloc_i_long
df_rho_gini_v <- ls_dis_solu_v$df_rho_gini
```


#### Mass Based Allocation

Allow for different mass for each type.

##### Mass C Allocation Run

```{r}
# Inputs
# 30 individuals 25 checks, half the amount is available
df_input_il_mass_c <- df_input_il_noninc %>%
  rename(A_il = c_A_il) %>%
  rename(alpha_il = c_alpha_il) %>%
  select(-v_A_il, -v_alpha_il)

# merge with mass, and set beta to 1
df_input_il_mass_c <- df_input_il_mass_c %>%
  mutate(beta_i = 1) %>%
  left_join(df_id %>% select(id_i, mass), by='id_i') %>%
  rename(mass_i = mass) %>%
  select(id_i, id_il, D_max_i, D_il, A_il, alpha_il, beta_i, mass_i) %>%
  ungroup()

# Solve with Function
ls_dis_solu_mass_c <- suppressWarnings(suppressMessages(
  ffp_opt_anlyz_rhgin_dis(ar_rho,
                          fl_dis_w_mass,
                          df_input_il_mass_c,
                          bl_df_alloc_il = FALSE,
                          bl_return_V = TRUE,
                          bl_return_allQ_V = FALSE,
                          bl_return_inner_V = FALSE,
                          svr_measure_i = 'mass_i')))
df_queue_il_long_mass_c <-ls_dis_solu_mass_c$df_queue_il_long
df_alloc_i_long_mass_c <- ls_dis_solu_mass_c$df_alloc_i_long
df_rho_gini_mass_c <- ls_dis_solu_mass_c$df_rho_gini
```

##### Mass V Allocation Run

Second Allocation based on life-time utility:

```{r}
# Inputs
# 30 individuals 25 checks, half the amount is available
df_input_il_mass_v <- df_input_il_noninc %>%
  rename(A_il = v_A_il) %>%
  rename(alpha_il = v_alpha_il) %>%
  select(-c_A_il, -c_alpha_il)

# merge with mass, and set beta to 1
df_input_il_mass_v <- df_input_il_mass_v %>%
  mutate(beta_i = 1) %>%
  left_join(df_id %>% select(id_i, mass), by='id_i') %>%
  rename(mass_i = mass) %>%
  ungroup()

# Solve with Function
ls_dis_solu_mass_v <- suppressWarnings(suppressMessages(
  ffp_opt_anlyz_rhgin_dis(ar_rho,
                          fl_dis_w_mass,
                          df_input_il_mass_v,
                          bl_df_alloc_il = FALSE,
                          bl_return_V = TRUE,
                          bl_return_allQ_V = FALSE,
                          bl_return_inner_V = FALSE,
                          svr_measure_i = 'mass_i')))
df_queue_il_long_mass_v <- ls_dis_solu_mass_v$df_queue_il_long
df_alloc_i_long_mass_v <- ls_dis_solu_mass_v$df_alloc_i_long
df_rho_gini_mass_v <- ls_dis_solu_mass_v$df_rho_gini
```

#### Summarize C Allocation Results

```{r}
REconTools::ff_summ_percentiles(df_queue_il_long_c, bl_statsasrows = FALSE)
REconTools::ff_summ_percentiles(df_queue_il_long_mass_c, bl_statsasrows = FALSE)
REconTools::ff_summ_percentiles(df_alloc_i_long_c, bl_statsasrows = FALSE)
REconTools::ff_summ_percentiles(df_alloc_i_long_mass_c, bl_statsasrows = FALSE)
```

#### Summarize V Allocation Results

```{r}
REconTools::ff_summ_percentiles(df_queue_il_long_v, bl_statsasrows = FALSE)
REconTools::ff_summ_percentiles(df_queue_il_long_mass_v, bl_statsasrows = FALSE)
REconTools::ff_summ_percentiles(df_alloc_i_long_v, bl_statsasrows = FALSE)
REconTools::ff_summ_percentiles(df_alloc_i_long_mass_v, bl_statsasrows = FALSE)
```

### Welfare Comparison Optimal vs Actual Allocation

#### C REV

2020 Consumption comparison:

```{r}
tb_rho_rev_mass_c <-
  PrjOptiAlloc::ffp_opt_anlyz_sodis_rev(ar_rho,
                          fl_dis_w_mass,
                          df_input_ib = df_input_ib_c,
                          df_queue_il_long_with_V = df_queue_il_long_mass_c,
                          svr_measure_i = 'mass_i')
tb_rho_rev_c <-
  PrjOptiAlloc::ffp_opt_anlyz_sodis_rev(ar_rho,
                          fl_dis_w,
                          df_input_ib = df_input_ib_c,
                          df_queue_il_long_with_V = df_queue_il_long_c)
```

```{r}
# Display Results
print(tb_rho_rev_mass_c)
print(tb_rho_rev_c)
```

#### V REV

2020 Value comparison:

```{r}
tb_rho_rev_mass_v <-
  PrjOptiAlloc::ffp_opt_anlyz_sodis_rev(ar_rho,
                          fl_dis_w_mass,
                          df_input_ib = df_input_ib_v,
                          df_queue_il_long_with_V = df_queue_il_long_mass_v,
                          svr_measure_i = 'mass_i')
tb_rho_rev_v <-
  PrjOptiAlloc::ffp_opt_anlyz_sodis_rev(ar_rho,
                          fl_dis_w,
                          df_input_ib = df_input_ib_v,
                          df_queue_il_long_with_V = df_queue_il_long_v)
```

Results
```{r}
# Display Results
print(tb_rho_rev_mass_v)
print(tb_rho_rev_v)
```


## Allocaiton Results Analysis

Join the allocation level dataframe with individual attributes, and possibly drop some ages to make graphs easier to read

```{r}
# Consider only subsets of ages for graphing
df_input_il_noninc_covar <- df_input_il_noninc %>%
  left_join(df_id, by = "id_i") %>%
  filter(kids <= 4) %>%
  mutate(ymin_group = as.numeric(ymin_group),
         kids = as.factor(kids),
         marital = as.factor(marital),
         checks = D_il)
# Summarize
df_alloc_i_long_covar_v <- df_alloc_i_long_mass_v %>%
  left_join(df_id, by = "id_i") %>%
  filter(kids <= 4)
df_alloc_i_long_covar_c <- df_alloc_i_long_mass_c %>%
  left_join(df_id, by = "id_i") %>%
  filter(kids <= 4)
```

Common Graph Notes

```{r}
stg_source = paste0('SNW 2020 Simulation')
stg_age = paste0('Age Between ', it_min_age, ' and ', it_max_age, '; Income Groups = ', it_inc_groups)
stg_caption = paste0(stg_source, '\n', stg_age)
```

### Table Allocation Quantity Comparison, Actual, Optimal Various

We have actual allocations, that is one column. Then we have optimal allocations based on c or V. And we have a number of attributes, y group, kids count, and marriage status. Show how actual and optimal allocations differ.

Note, df_input_ib_v and df_input_ib_c have the same actual_checks numbers:

```{r}
df_alloc_i_long_covar_v <- df_alloc_i_long_covar_v %>%
  left_join(df_input_ib_v %>% select(id_i, actual_checks), by='id_i')
df_alloc_i_long_covar_c <- df_alloc_i_long_covar_c %>%
  left_join(df_input_ib_c %>% select(id_i, actual_checks), by='id_i')
```

V optimal and v actual:

```{r}
df_alloc_i_long_covar_v %>%
  select(D_star_i, actual_checks, kids, marital, ymin_group) %>%
  arrange(ymin_group, marital, kids)
```

For the easy of graphing, generate stacked dataframe where D_star_i and actual_checks are one variable, but tagged by actual and optimal.

```{r}
# v table
df_alloc_i_long_covar_v <- df_alloc_i_long_covar_v %>%
  rename(allocate_check_optimal = D_star_i,
         allocate_check_actual = actual_checks) %>%
  pivot_longer(cols = starts_with('allocate_check_'),
               names_to = c('allocate_type'),
               names_pattern = paste0("allocate_check_(.*)"),
               values_to = "checks")
# c table
df_alloc_i_long_covar_c <- df_alloc_i_long_covar_c %>%
  rename(allocate_check_optimal = D_star_i,
         allocate_check_actual = actual_checks) %>%
  pivot_longer(cols = starts_with('allocate_check_'),
               names_to = c('allocate_type'),
               names_pattern = paste0("allocate_check_(.*)"),
               values_to = "checks")
```


### Graph Welfare Comparison Figure

```{r}

# x-labels
x.labels <- c('λ=0.99', 'λ=0.90', 'λ=0', 'λ=-10', 'λ=-100')
x.breaks <- c(0.01, 0.10, 1, 10, 100)

# title line 2
# title_line1 <- sprintf("Percentage of Training Spots Misallocated, NSW Lalonde (AER, 1986)")
# title_line2 <- sprintf("REV (Resource Equivalent Variation) Along Planner Spectrum")

st_title <- sprintf(paste0('C Allocation: How much Fewer Resources are Needed (Shares) to Achieve the Same Welfare'))
title_line1 <- sprintf("Covid Check: Compare Feasible vs Actual Allocations")

# Graph Results--Draw
line.plot <- tb_rho_rev_mass_c %>%
  mutate(REV = 100*REV)  %>%
  mutate(one_minus_rho = 1 - rho_val)  %>%
  ggplot(aes(x=one_minus_rho, y=REV)) +
  geom_line() +
  geom_point() +
  # geom_vline(xintercept=c(1), linetype="dotted") +
  labs(title = st_title,
       subtitle = paste0(title_line1),
       x = 'log10 Rescale of λ, Log10(1-λ)\nλ=1 Utilitarian (Maximize Average), λ=-infty Rawlsian (Maximize Minimum)',
       y = paste0('100 x REV (Resource Equivalent Variations)'),
       caption = 'SNW 2020 Life Cycle Simulations.') +
  scale_x_continuous(trans='log10', labels = x.labels, breaks = x.breaks) +
  theme_bw(base_size=8) +
  ylim(0, 100)
# +
#   guides(colour=FALSE)


# Print
print(line.plot)

spt_img_save <- 'img/'
bl_save_img <- FALSE
if (bl_save_img) {
  snm_cnts <- 'opti_vs_unif_rev.png'
  png(paste0(spt_img_save, snm_cnts),
      width = 135, height = 96, units='mm', res = 300, pointsize=7)
  print(line.plot)
  dev.off()
}
```

### Table C Allocation Amounts by Attributes

Summarize check level statistics by key attributes:

```{r}
ls_svr_groups <- c('ymin_group', 'marital', 'kids')
for (svr_group in ls_svr_groups) {

  # Group by variable
  print(paste0('current group = ', svr_group))

  # Summarize
  df <- df_alloc_i_long_covar_c
  vars.group <- c('rho_val', svr_group, 'allocate_type')
  var.numeric <- 'checks'
  str.stats.group <- 'allperc'
  ar.perc <- c(0.10, 0.25, 0.50, 0.75, 0.90)
  ls_summ_by_group <- REconTools::ff_summ_bygroup(
    df, vars.group, var.numeric, str.stats.group, ar.perc)
  print(ls_summ_by_group$df_table_grp_stats)

}
```

### Table V Allocation Amounts by Attributes

Summarize check level statistics by key attributes:

```{r}
ls_svr_groups <- c('ymin_group', 'marital', 'kids')
for (svr_group in ls_svr_groups) {

  # Group by variable
  print(paste0('current group = ', svr_group))

  # Summarize
  df <- df_alloc_i_long_covar_v
  vars.group <- c('rho_val', svr_group, 'allocate_type')
  var.numeric <- 'checks'
  str.stats.group <- 'allperc'
  ar.perc <- c(0.10, 0.25, 0.50, 0.75, 0.90)
  ls_summ_by_group <- REconTools::ff_summ_bygroup(
    df, vars.group, var.numeric, str.stats.group, ar.perc)
  print(ls_summ_by_group$df_table_grp_stats)

}
```

### Graph Mass at Points

```{r}
# graph mean check amount by income, marital status and kids counts
lineplot_c <- df_alloc_i_long_covar_c %>%
  filter(rho_val == ar_rho[1]) %>% ungroup() %>%
  # filter(marital == 1) %>%
  mutate(ymin_group = as.numeric(ymin_group),
         kids = as.factor(kids),
         marital = as.factor(marital)) %>%
    ggplot(aes(x=ymin_group, y=mass ,
               colour=kids,
               shape=marital)) +
        facet_wrap( ~ marital + kids, ncol=5) +
        geom_point(size=3) +
        labs(title = paste0('Mass At Each Kids/Marry/Income Points, ',
                      st_file_type),
             subtitle = subtitle,
             x = 'Income Group',
             y = 'Mass for this Group',
             caption = stg_caption)
print(lineplot_c)
```

### Graph Marginal Consumption

#### Marginal Change in Log of Consumption Levels

1. select first check row, and keep just A, C with 0 checks
2. up A and alpha, C with 44 checks
3. take log of c and difference


```{r}
# 1. Generate zero check c
df_input_il_noninc_covar_difflogc <-
  rbind(df_input_il_noninc_covar %>%
          filter(checks == 1) %>%
          mutate(checks = 0) %>%
          mutate(c_A_il_log = log(c_A_il)),
        df_input_il_noninc_covar %>%
          mutate(c_A_il_log = log(c_A_il + c_alpha_il))) %>%
  arrange(id_i, svr_checks) %>%
  group_by(id_i) %>%
  mutate(c_A_il_log_diff = c_A_il_log - lag(c_A_il_log))

# 2. Graph Results
lineplot_difflogc <- df_input_il_noninc_covar_difflogc %>%
    ggplot(aes(x=ymin_group, y=c_A_il_log_diff,
               colour=checks,
               shape=kids)) +
        facet_wrap( ~ marital + kids, ncol=5, labeller = label_wrap_gen(multi_line=FALSE)) +
        geom_point(size=1) +
        # scale_y_continuous(trans='log') +
        labs(title = paste0('Log(C(checks))-log(C(checks-1)), Conditional on: Marry+Kids+Income, ',
                      st_file_type, '\n', 'Top Row = Unmarried, Bottom Row = Married, Dark Blue = check 1, Light Blue = Final Check'),
             subtitle = subtitle,
             x = 'Income Group',
             y = 'Log(Total C with X Checks) - Log(Total C with X-1 Checks)',
             caption = stg_caption)
print(lineplot_difflogc)
```

#### Log of Marginal Change in Consumption

Graph out the marginal consumption gain for each check.

```{r}
# df_input_il_noninc %>%
#   left_join(df_id, by = "id_i")

  # graph mean check amount by income, marital status and kids counts
lineplot_c <- df_input_il_noninc_covar %>%
    ggplot(aes(x=ymin_group, y=log(c_alpha_il),
               colour=checks,
               shape=kids)) +
        facet_wrap( ~ marital + kids, ncol=5, labeller = label_wrap_gen(multi_line=FALSE)) +
        geom_point(size=1) +
        # scale_y_continuous(trans='log') +
        labs(title = paste0('Marginal Consumption Gain Each Check, Conditional on: Marry+Kids+Income, ',
                      st_file_type, '\n', 'Top Row = Unmarried, Bottom Row = Married, Dark Blue = check 1, Light Blue = Final Check'),
             subtitle = subtitle,
             x = 'Income Group',
             y = 'Log(Marginal Consumption Gain Per Check)',
             caption = stg_caption)
print(lineplot_c)
```

### Graph Consumption Based Allocation Figure

Generate the needed dataframe, averaging over ages, averages by ymin, marital status, and kids count:

```{r}
# graph mean check amount by income, marital status and kids counts
lineplot_c <- df_alloc_i_long_covar_c %>%
  filter(rho_val == ar_rho[1]) %>% ungroup() %>%
  mutate(ymin_group = as.numeric(ymin_group),
         kids = as.factor(kids),
         marital = as.factor(marital)) %>%
    ggplot(aes(x=ymin_group, y=checks,
               colour=allocate_type,
               shape=allocate_type,
               linetype=allocate_type)) +
        facet_wrap( ~ marital + kids, ncol=5, labeller = label_wrap_gen(multi_line=FALSE)) +
        geom_point(size=3) +
        geom_line() +
        labs(title = paste0('Optimize Expected 2020 Consumption, Conditional on: Marry+Kids+Income, ',
                      st_file_type, '\n', 'Colors Represent Actual Policy versus Optimal Policy'),
             subtitle = subtitle,
             x = 'Income Group',
             y = 'Number of Checks',
             caption = stg_caption) +
  theme(
    legend.position = c(0.14, 0.9), # c(0,0) bottom left, c(1,1) top-right.
    legend.background = element_rect(fill = "white", colour = "black", linetype='solid')
  )

print(lineplot_c)
```

### Graph Value Marginal Per Check

Graph out the marginal value for each check.

```{r}
# df_input_il_noninc %>%
#   left_join(df_id, by = "id_i")

  # graph mean check amount by income, marital status and kids counts
lineplot_c <- df_input_il_noninc_covar %>%
    ggplot(aes(x=ymin_group, y=log(v_alpha_il),
               colour=checks,
               shape=kids)) +
        facet_wrap( ~ marital + kids, ncol=5) +
        geom_point(size=1) +
        labs(title = paste0('Marginal Value Gain Each Check, Conditional on: Marry+Kids+Income, ',
                      st_file_type, '\n', 'Top Row = Unmarried, Bottom Row = Married, Dark Blue = check 1, Light Blue = Final Check'),
             subtitle = subtitle,
             x = 'Income Group',
             y = 'Log(Marginal Value Gain Per Check)',
             caption = stg_caption)
print(lineplot_c)
```

### Graph Value Based Allocation Figure

```{r}
# graph mean check amount by income, marital status and kids counts
lineplot_v <- df_alloc_i_long_covar_v %>%
  filter(rho_val == ar_rho[1]) %>% ungroup() %>%
  mutate(ymin_group = as.numeric(ymin_group),
         kids = as.factor(kids),
         marital = as.factor(marital)) %>%
    ggplot(aes(x=ymin_group, y=checks,
               colour=allocate_type,
               shape=kids,
               linetype=marital)) +
        facet_wrap( ~ marital + kids, ncol=5) +
        geom_point(size=3) +
        geom_line() +
        labs(title =
               paste0('Optimize Expected 2020 Value, Conditional on: Marry+Kids+Income, ',
                      st_file_type, '\n', 'Colors Represent Actual Policy versus Optimal Policy'),
             subtitle = subtitle,
             x = 'Income Group',
             y = 'Number of Checks',
             caption = stg_caption)
print(lineplot_v)
```


## Print Results to CSV

### Print Allocation Results

Print Allocation Results in Two Ways, Row based, with actual, first, and second round allocations as columns. And this table is outputed, at different levels of aggregations. where the allocation columns are outputed as different weighted means. Also compute fraction 0, fraction at within group max.

```{r}

df_alloc_all <- rbind(df_alloc_i_long_covar_v %>%
  filter(rho_val == ar_rho[1]) %>%
  mutate(allocate_type = case_when(allocate_type == 'optimal' ~ 'optimalv',
                                   TRUE ~ allocate_type)),
  df_alloc_i_long_covar_c %>%
  filter(rho_val == ar_rho[1]) %>%
  filter(allocate_type == 'optimal') %>%
  mutate(allocate_type = case_when(allocate_type == 'optimal' ~ 'optimalc',
                                   TRUE ~ allocate_type))) %>%
  arrange(id_i, allocate_type) %>%
  select(-rho, -F_star_i, -EH_star_i, -survive) %>%
  select(id_i, rho_val, everything())

df_alloc_all <- df_alloc_all %>%
  pivot_wider(names_from = allocate_type,
              values_from = checks)

# export
write.csv(df_alloc_all,
  paste0(srt_csv_test_path, "df_alloc_all.csv"),
  row.names = TRUE)

```

Export Grouped Average Statistics:

```{r}
ls_svr_groups <- c('ymin_group', 'marital', 'kids')
for (svr_group in ls_svr_groups) {

  # group mean
  df_alloc_combine_group_mean <- df_alloc_all %>%
    ungroup() %>% group_by(!!sym(svr_group)) %>%
    summarize(actual_mean = sum(actual*mass)/sum(mass),
              optimalc_mean = sum(optimalc*mass)/sum(mass),
              optimalv_mean = sum(optimalv*mass)/sum(mass),
              mass_sum = sum(mass))

  # Export
  write.csv(df_alloc_combine_group_mean,
    paste0(srt_csv_test_path, "df_alloc_",svr_group, ".csv"),
    row.names = TRUE)

  # All but Group mean
  ls_svr_groups_oneless <- ls_svr_groups[ls_svr_groups != svr_group]
  df_alloc_combine_group_mean_oneless <- df_alloc_all %>%
    ungroup() %>% group_by(!!!syms(ls_svr_groups_oneless)) %>%
    summarize(actual_mean = sum(actual*mass)/sum(mass),
              optimalc_mean = sum(optimalc*mass)/sum(mass),
              optimalv_mean = sum(optimalv*mass)/sum(mass),
              mass_sum = sum(mass))

  # Export
  write.csv(df_alloc_combine_group_mean_oneless,
    paste0(srt_csv_test_path, "df_alloc_",svr_group,"_without.csv"),
    row.names = TRUE)

}
```

### Print and save MASS REV results:

```{r}
# Save REV to table, Stack them
tb_rho_rev_mass_v_tab <- tb_rho_rev_mass_v %>%
  mutate(objective = 'vlife',
         constraint = 'feasible',
         allocround = 'first')
tb_rho_rev_mass_c_tab <- tb_rho_rev_mass_c %>%
  mutate(objective = 'c2020',
         constraint = 'feasible',
         allocround = 'first')
# Stack frames
tb_rho_rev_mass_v_c_tab <- rbind(tb_rho_rev_mass_v_tab, tb_rho_rev_mass_c_tab)
# export
write.csv(tb_rho_rev_mass_v_c_tab,
  paste0(srt_csv_test_path, "rev_feasible.csv"),
  row.names = TRUE)
```
